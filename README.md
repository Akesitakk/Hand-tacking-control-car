This project focused on developing an AI-based system to control a motorized vehicle using hand gestures. The setup involved hardware components like an Arduino UNO, DC motors, motor drivers, Mecanum wheels, an acrylic board, and a rechargeable lithium-ion battery. The software side utilized libraries such as Mediapipe, Serial, CV2 (OpenCV), and Time. The system worked by using a camera to detect hand gestures, with Mediapipe handling the hand detection and tracking. Specific gestures were mapped to different motor commands, ranging from stopping to moving in various directions. The system demonstrated a high confidence level, with a score between 95% and 99% for gesture recognition. However, the project encountered challenges, including real-time data transmission issues with the Arduino, a broken motor, and initial difficulties in using a teachable machine for gesture recognition. Despite these obstacles, the project successfully showcased the application of AI in gesture-based motor control.


Done by: Akesit, Kunlanith, Pann, Paveetida, Rattapol, Saranya, Suchaya, Theedhat
